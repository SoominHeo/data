So security is two different things: it's a feeling, and it's a reality.

And they're different.

You could feel secure even if you're not.

And you can be secure even if you don't feel it.

Really, we have two separate concepts mapped onto the same word.

And what I want to do in this talk is to split them apart -- figuring out when they diverge and how they converge.

And language is actually a problem here.

There aren't a lot of good words for the concepts we're going to talk about. 

So if you look at security from economic terms, it's a trade-off.

Every time you get some security, you're always trading off something.

Whether this is a personal decision -- whether you're going to install a burglar alarm in your home -- or a national decision -- where you're going to invade some foreign country -- you're going to trade off something, either money or time, convenience, capabilities, maybe fundamental liberties.

And the question to ask when you look at a security anything is not whether this makes us safer, but whether it's worth the trade-off.

You've heard in the past several years, the world is safer because Saddam Hussein is not in power.

That might be true, but it's not terribly relevant.

The question is, was it worth it?

And you can make your own decision, and then you'll decide whether the invasion was worth it.

That's how you think about security -- in terms of the trade-off. 

Now there's often no right or wrong here.

Some of us have a burglar alarm system at home, and some of us don't.

And it'll depend on where we live, whether we live alone or have a family, how much cool stuff we have, how much we're willing to accept the risk of theft.

In politics also, there are different opinions.

A lot of times, these trade-offs are about more than just security, and I think that's really important.

Now people have a natural intuition about these trade-offs.

We make them every day -- last night in my hotel room, when I decided to double-lock the door, or you in your car when you drove here, when we go eat lunch and decide the food's not poison and we'll eat it.

We make these trade-offs again and again, multiple times a day.

Every species does it.

So you'd think that us, as a successful species on the planet -- you, me, everybody -- would be really good at making these trade-offs.

Yet it seems, again and again, that we're hopelessly bad at it.

And I think that's a fundamentally interesting question. 

I'll give you the short answer.

The answer is, we respond to the feeling of security and not the reality.

Now most of the time, that works.

Most of the time, feeling and reality are the same.

Certainly that's true for most of human prehistory.

We've developed this ability because it makes evolutionary sense.

One way to think of it is that we're highly optimized for risk decisions that are endemic to living in small family groups in the East African highlands in 100,000 B.C.

2010 New York, not so much. 

Now there are several biases in risk perception.

So I'll give you four.

The unknown is perceived to be riskier than the familiar.

One example would be, people fear kidnapping by strangers when the data supports kidnapping by relatives is much more common.

This is for children.

And the fourth is people underestimate risks in situations they do control and overestimate them in situations they don't control.

So once you take up skydiving or smoking, you downplay the risks.

If a risk is thrust upon you -- terrorism was a good example -- you'll overplay it because you don't feel like it's in your control. 

There are a bunch of other of these biases, these cognitive biases, that affect our risk decisions.

There's the availability heuristic, which basically means we estimate the probability of something by how easy it is to bring instances of it to mind.

So you can imagine how that works.

If you hear a lot about tiger attacks, there must be a lot of tigers around.

You don't hear about lion attacks, there aren't a lot of lions around.

(Laughter) When something is so common, it's no longer news -- car crashes, domestic violence -- those are the risks you worry about. 

(Laughter) When something is so common, it's no longer news -- car crashes, domestic violence -- those are the risks you worry about. 

We're also a species of storytellers.

We respond to stories more than data.

And there's some basic innumeracy going on.

I mean, the joke "One, Two, Three, Many" is kind of right.

We're really good at small numbers.

And what these cognitive biases do is they act as filters between us and reality.

And the result is that feeling and reality get out of whack, they get different.

I write a lot about "security theater," which are products that make people feel secure, but don't actually do anything.

There's no real word for stuff that makes us secure, but doesn't make us feel secure.

Maybe it's what the CIA's supposed to do for us. 

And there are two ways to do this.

So what makes people notice?

Now we all know the crime rate in our neighborhood, because we live there, and we get a feeling about it that basically matches reality.

Security theater's exposed when it's obvious that it's not working properly.

Okay, so what makes people not notice?

Well, a poor understanding.

If you don't understand the risks, you don't understand the costs, you're likely to get the trade-off wrong, and your feeling doesn't match reality.

Not enough examples.

There's an inherent problem with low probability events.

If, for example, terrorism almost never happens, it's really hard to judge the efficacy of counter-terrorist measures.

This is why you keep sacrificing virgins, and why your unicorn defenses are working just great.

There aren't enough examples of failures.

Also, feelings that are clouding the issues -- the cognitive biases I talked about earlier, fears, folk beliefs, basically an inadequate model of reality. 

So let me complicate things.

I have feeling and reality.

Feeling and model in our head, reality is the outside world.

It doesn't change; it's real.

That's basically the difference.

You don't need a model.

But in a modern and complex world, you need models to understand a lot of the risks we face.

So this model is an intelligent representation of reality.

It's, of course, limited by science, by technology.

We couldn't have a germ theory of disease before we invented the microscope to see them.

It's limited by our cognitive biases.

But it has the ability to override our feelings. 

We get them from religion, from culture, teachers, elders.

A couple years ago, I was in South Africa on safari.

The tracker I was with grew up in Kruger National Park.

He had some very complex models of how to survive.

And it depended on if you were attacked by a lion or a leopard or a rhino or an elephant -- and when you had to run away, and when you couldn't run away, and when you had to climb a tree -- when you could never climb a tree.

I was born in New York City.

I could have taken him to New York, and he would have died in a day.

(Laughter) Because we had different models based on our different experiences. 

(Laughter) Because we had different models based on our different experiences. 

Models can come from the media, from our elected officials.

Think of models of terrorism, child kidnapping, airline safety, car safety.

Models can come from industry.

The two I'm following are surveillance cameras, ID cards, quite a lot of our computer security models come from there.

A lot of models come from science.

Health models are a great example.

Think of cancer, of bird flu, swine flu, SARS.

All of our feelings of security about those diseases come from models given to us, really, by science filtered through the media.

So models can change.

Models are not static.

As we become more comfortable in our environments, our model can move closer to our feelings. 

So an example might be, if you go back 100 years ago when electricity was first becoming common, there were a lot of fears about it.

I mean, there were people who were afraid to push doorbells, because there was electricity in there, and that was dangerous.

For us, we're very facile around electricity.

It hasn't changed as we were growing up.

And we're good at it.

Or think of the risks on the Internet across generations -- how your parents approach Internet security, versus how you do, versus how our kids will.

Models eventually fade into the background.

Intuitive is just another word for familiar. 

So as your model is close to reality, and it converges with feelings, you often don't know it's there.

So a nice example of this came from last year and swine flu.

When swine flu first appeared, the initial news caused a lot of overreaction.

Now it had a name, which made it scarier than the regular flu, even though it was more deadly.

And people thought doctors should be able to deal with it.

So there was that feeling of lack of control.

And those two things made the risk more than it was.

By autumn, people thought the doctors should have solved this already.

And there's kind of a bifurcation -- people had to choose between fear and acceptance -- actually fear and indifference -- they kind of chose suspicion.

This kind of thing happens a lot. 

I'm going to give one more complication.

We have feeling, model, reality.

I have a very relativistic view of security.

I think it depends on the observer.

And most security decisions have a variety of people involved.

And stakeholders with specific trade-offs will try to influence the decision.

And I call that their agenda.

And you see agenda -- this is marketing, this is politics -- trying to convince you to have one model versus another, trying to convince you to ignore a model and trust your feelings, marginalizing people with models you don't like.

This is not uncommon.

An example, a great example, is the risk of smoking.

Think about seat belts.

When I was a kid, no one wore a seat belt.

Nowadays, no kid will let you drive if you're not wearing a seat belt.

Compare that to the airbag debate -- probably about 30 years behind. 

Models are hard to dislodge.

So evidence against our model, we're likely to ignore, even if it's compelling.

It has to get very compelling before we'll pay attention.

New models that extend long periods of time are hard.

Global warming is a great example.

We're terrible at models that span 80 years.

We can do to the next harvest.

We can often do until our kids grow up.

But 80 years, we're just not good at.

So it's a very hard model to accept.

Eventually, the new model will replace the old model. 

Strong feelings can create a model.

September 11th created a security model in a lot of people's heads.

Also, personal experiences with crime can do it, personal health scare, a health scare in the news.

You'll see these called flashbulb events by psychiatrists.

They can create a model instantaneously, because they're very emotive. 

We rely on government agencies to tell us what pharmaceuticals are safe.

I relied on some other group to determine whether my plane was safe to fly.

It's a model we just accept pretty much by faith.

And that's okay. 

Now, what we want is people to get familiar enough with better models -- have it reflected in their feelings -- to allow them to make security trade-offs.

Now when these go out of whack, you have two options.

One, you can fix people's feelings, directly appeal to feelings.

It's manipulation, but it can work.

The second, more honest way is to actually fix the model.

Change happens slowly.

Some of this stuff is hard.

I mean really though, information seems like our best hope. 

And I lied.

We live in a technological world; reality changes all the time.

So we might have -- for the first time in our species -- feeling chases model, model chases reality, reality's moving -- they might never catch up.

We don't know.

But in the long-term, both feeling and reality are important.

And I want to close with two quick stories to illustrate this. 

Someone else bought it and died.

This terrified people.

There were a couple of copycat attacks.

There wasn't any real risk, but people were scared.

And this is how the tamper-proof drug industry was invented.

Those tamper-proof caps, that came from this.

It's complete security theater.

But it made people feel better.

It made their feeling of security more match the reality. 

Last story, a few years ago, a friend of mine gave birth.

I visit her in the hospital.

I said, "Well, that's kind of neat.

I wonder how rampant baby snatching is out of hospitals."

(Laughter) 

(Laughter) 

What's important is that they be about the same.

It's important that, if our feelings match reality, we make better security trade-offs. 

Thank you. 

