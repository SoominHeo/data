That technology is simulating humans.

It's simulated humans with a simulated body and a simulated nervous system to control that body.

Now, before I talk more about that technology, let's have a quick look at what human characters look like at the moment in computer games.

This is a clip from a game called "Grand Theft Auto 3."

We already saw that briefly yesterday.

And what you can see is -- it is actually a very good game.

It's one of the most successful games of all time.

But what you'll see is that all the animations in this game are very repetitive.

The reason for that is that these characters are actually not real characters.

They are a graphical visualization of a character. 

To produce these animations, an animator at a studio has to anticipate what's going to happen in the actual game, and then has to animate that particular sequence.

So, he or she sits down, animates it, and tries to anticipate what's going to happen, and then these particular animations are just played back at appropriate times in the computer game.

Now, the result of that is that you can't have real interactivity.

There's no real emergence there. 

And thirdly, as I said, most of the animations are very repetitive because of that.

Now, the only way to get around that is to actually simulate the human body and to simulate that bit of the nervous system of the brain that controls that body.

And maybe, if I could have you for a quick demonstration to show what the difference is -- because, I mean, it's very, very trivial.

If I push Chris a bit, like this, for example, he'll react to it.

If I push him from a different angle, he'll react to it differently, and that's because he has a physical body, and because he has the motor skills to control that body.

Torsten Reil: That's it, yes.

So, that's what we're trying to simulate -- not Chris specifically, I should say, but humans in general.

Now, we started working on this a while ago at Oxford University, and we tried to start very simply.

So, it's subject to gravity, has joints, etc.

If you just run the simulation, it will just collapse, like this.

The tricky bit is now to put an AI controller in it that actually makes it work.

And for that, we use the neural network, which we based on that part of the nervous system that we have in our spine that controls walking in humans.

It's called the central pattern generator.

We heard about those already yesterday, and I suppose that most of you are familiar with that already.

But, just briefly, the concept is that you create a large number of different individuals -- neural networks, in this case -- all of which are random at the beginning.

You hook these up -- in this case, to the virtual muscles of that two-legged creature here -- and hope that it does something interesting.

Those are then selected by the algorithm, reproduced with mutation and recombinations to introduce sex as well.

And you repeat that process over and over again, until you have something that walks -- in this case, in a straight line, like this.

So that was the idea behind this.

And this is an example of a successful evolutionary run.

So, what you'll see in a moment is a very simple biped that's learning how to walk using artificial evolution.

Now, after five generations of applying evolutionary process, the genetic algorithm is getting a tiny bit better. 

Now, at this stage, it also became clear that this could be very exciting for things like computer games or online worlds.

Now, the interesting bit is, if I move the obstacle a tiny bit to the right, which is what I'm doing now, here, it will fall over it in a completely different way.

And again, if you move the obstacle a tiny bit, it'll again fall differently. 

Thanks.

We hired a team of physicists, software engineers and biologists to work on this, and the first thing we had to work on was to create the human body, basically.

It's got to be relatively fast, so you can run it on a normal machine, but it's got to be accurate enough, so it looks good enough, basically. 

So we put quite a bit of biomechanical knowledge into this thing, and tried to make it as realistic as possible.

What you see here on the screen right now is a very simple visualization of that body.

I should add that it's very simple to add things like hair, clothes, etc., but what we've done here is use a very simple visualization, so you can concentrate on the movement.

Now, what I'm going to do right now, in a moment, is just push this character a tiny bit and we'll see what happens.

I'll show you this again.

First, starting with a push from the right.

This is all slow motion, by the way, so we can see what's going on.

Now, the angle will have changed a tiny bit, so you can see that the reaction is different.

And now from the left -- and it falls differently.

And this is what happens. 

It's nothing we had to do about this.

We just took this character that I just talked about, put it on a slippery surface, and this is what you get out of it.

You can see, it's always reacting.

Only, I think it's quite a big blow again.

You feel kind of sorry for that thing, and we've seen it so many times now that we don't really care any more. 

So that you don't have a character that looks limp, but actually a character that you can use in an action film straight away, that looks kind of alive in midair as well.

That's one angle; here's another angle.

We now think that the realism we're achieving with this is good enough to be used in films. 

So this is exactly the same behavior that you saw, but in a slightly better rendered version.

So if you look at the character carefully, you see there are lots of body movements going on, none of which you have to animate like in the old days.

Animators had to actually animate them.

This is all happening automatically in the simulation.

At the moment, doing something like this by hand would take you probably a couple of days. 

It's a very simple behavior that shows you the power of this approach.

In this case, the character's hands are fixed to a particular point in space, and all we've told the character to do is to struggle.

You feel kind of sorry for the guy.

It's even worse -- and that is another video I just got last night -- if you render that a bit more realistically. 

Now, I'm showing this to you just to show you how organic it actually can feel, how realistic it can look.

But what we found over the past few months is that this approach -- that we're pretty much standard upon -- is incredibly powerful.

We are ourselves surprised what you actually get out of the simulations.

There's very often very surprising behavior that you didn't predict before. 

There's so many things we can do with this right now.

The first thing, as I said, is going to be virtual stuntmen.

Several studios are using this software now to produce virtual stuntmen, and they're going to hit the screen quite soon, actually, for some major productions.

The second thing is video games.

With this technology, video games will look different and they will feel very different.

For the first time, you'll have actors that really feel very interactive, that have real bodies that really react.

I think that's going to be incredibly exciting.

Probably starting with sports games, which are going to become much more interactive.

But I particularly am really excited about using this technology in online worlds, like there, for example, that Tom Melcher has shown us.

The degree of interactivity you're going to get is totally different, I think, from what you're getting right now. 

A third thing we are looking at and very interested in is simulation.

As you probably know, it's very difficult to predict what the outcome of an operation is if you try and correct the gait. 

The classic quote is, I think, it's unpredictable at best, is what people think right now, is the outcome.

Now, what we want to do with our software is allow our surgeons to have a tool.

We're going to simulate the gait of a particular child and the surgeon can then work on that simulation and try out different ways to improve that gait, before he actually commits to an actual surgery.

That's one project we're particularly excited about, and that's going to start next month.

Just finally, this is only just the beginning.

We can only do several behaviors right now.

The AI isn't good enough to simulate a full human body.

The body yes, but not all the motor skills that we have.

We do have one unintentional dancer actually, the last thing I'm going to show you.

This was an AI contour that was produced and evolved -- half-evolved, I should say -- to produce balance, basically.

So, you kick the guy and the guy's supposed to counter-balance.

So, this was not something we actually put in there.

And what you see after a while -- I think he even goes into a climax right at the end.

And I think -- there you go. 

Thanks. 

TR: Thanks. 

