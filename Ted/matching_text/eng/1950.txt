It seems that there's not just one person who thinks that these problems are important. 

The first is -- death is a big problem.

If you look at the statistics, the odds are not very favorable to us.

So far, most people who have lived have also died.

Roughly 90 percent of everybody who has been alive has died by now.

The annual death rate, then, becomes 56 million.

Sometimes, we don't see a problem because either it's too familiar or it's too big.

Can't see it because it's too big.

I think death might be both too familiar and too big for most people to see it as a problem. 

I've talked for three minutes.

So that would be, roughly, 324 people have died since I've begun speaking.

People like -- it's roughly the population in this room has just died.

Suppose we approximated one person with one book?

Now, of course, this is an underestimation.

A person's lifetime of learning and experience is a lot more than you could put into a single book.

But let's suppose we did this.

Library of Congress holds 18 million volumes.

We are upset about the burning of the Library of Alexandria.

It's one of the great cultural tragedies that we remember, even today.

But this is the equivalent of three Libraries of Congress -- burnt down, forever lost -- each year. 

So that's the first big problem.

And I wish Godspeed to Aubrey de Grey, and other people like him, to try to do something about this as soon as possible.

Existential risk -- the second big problem.

Existential risk is a threat to human survival, or to the long-term potential of our species.

Now, why do I say that this is a big problem?

But there have been four studies -- one by John Lesley, wrote a book on this.

He estimated a probability that we will fail to survive the current century: 50 percent.

Similarly, the Astronomer Royal, whom we heard speak yesterday, also has a 50 percent probability estimate.

Another author doesn't give any numerical estimate, but says the probability is significant that it will fail.

I wrote a long paper on this.

Everybody who has looked at this and studied it agrees. 

If we could eventually colonize a chunk of the universe -- the Virgo supercluster -- maybe it will take us 100 million years to get there, but if we go extinct we never will.

Then, even a one percentage point reduction in the extinction risk could be equivalent to this astronomical number -- 10 to the power of 32. 

So if you take into account future generations as much as our own, every other moral imperative of philanthropic cost just becomes irrelevant.

Or is it possible to find something a little bit more inspiring to work towards?

If we want to achieve this, what, in the world, would have to change?

It's worth recalling that there are a lot of other modification technologies and enhancement technologies that we use.

Mood modifiers have been used from time immemorial -- caffeine, alcohol, nicotine, immune system enhancement, vision enhancement, anesthetics -- we take that very much for granted, but just think about how great progress that is -- like, having an operation before anesthetics was not fun.

Contraceptives, cosmetics and brain reprogramming techniques -- that sounds ominous, 

It's been done in voles.

Now, why is that a good thing to do?

Thanks. 

