I work with a bunch of mathematicians, philosophers and computer scientists, and we sit around and think about the future of machine intelligence, among other things.

Some people think that some of these things are sort of science fiction-y, far out there, crazy.

(Laughter) This is the normal way for things to be. 

Think about if Earth was created one year ago, the human species, then, would be 10 minutes old.

The industrial era started two seconds ago.

Another way to look at this is to think of world GDP over the last 10,000 years, I've actually taken the trouble to plot this for you in a graph.

It looks like this.

(Laughter) It's a curious shape for a normal condition.

(Laughter) 

But I like to think back further to the ultimate cause. 

One is a little larger, it maybe also has a few tricks in the exact way it's wired.

We know that complicated mechanisms take a long time to evolve.

So a bunch of relatively minor changes take us from Kanzi to Witten, from broken-off tree branches to intercontinental ballistic missiles. 

So this then seems pretty obvious that everything we've achieved, and everything we care about, depends crucially on some relatively minor changes that made the human mind.

Some of my colleagues think we're on the verge of something that could cause a profound change in that substrate, and that is machine superintelligence.

Artificial intelligence used to be about putting commands in a box.

You would have human programmers that would painstakingly handcraft knowledge items.

You build up these expert systems, and they were kind of useful for some purposes, but they were very brittle, you couldn't scale them.

Basically, you got out only what you put in.

But since then, a paradigm shift has taken place in the field of artificial intelligence. 

Today, the action is really around machine learning.

So rather than handcrafting knowledge representations and features, we create algorithms that learn, often from raw perceptual data.

Now of course, A.I.

The cortex still has some algorithmic tricks that we don't yet know how to match in machines. 

A couple of years ago, we did a survey of some of the world's leading A.I.

Now, it could happen much, much later, or sooner, the truth is nobody really knows. 

What we do know is that the ultimate limit to information processing in a machine substrate lies far outside the limits in biological tissue.

But even a present-day transistor operates at the Gigahertz.

So the potential for superintelligence lies dormant in matter, much like the power of the atom lay dormant throughout human history, patiently waiting there until 1945.

In this century, scientists may learn to awaken the power of artificial intelligence.

And I think we might then see an intelligence explosion. 

Now most people, when they think about what is smart and what is dumb, I think have in mind a picture roughly like this.

So at one end we have the village idiot, and then far over at the other side we have Ed Witten, or Albert Einstein, or whoever your favorite guru is.

And then, after many, many more years of really hard work, lots of investment, maybe eventually we get to chimpanzee-level artificial intelligence.

And then, after even more years of really, really hard work, we get to village idiot artificial intelligence.

And a few moments later, we are beyond Ed Witten.

The train doesn't stop at Humanville Station.

It's likely, rather, to swoosh right by. 

And yet, the fate of Kanzi and his pals depends a lot more on what we humans do than on what the chimpanzees do themselves.

Once there is superintelligence, the fate of humanity may depend on what the superintelligence does.

What this means is basically a telescoping of the future.

All of this superintelligence could develop, and possibly quite rapidly. 

A superintelligence is a really strong optimization process.

It's extremely good at using available means to achieve a state in which its goal is realized.

This means that there is no necessary conenction between being highly intelligent in this sense, and having an objective that we humans would find worthwhile or meaningful. 

And notice that this gives the A.I.s an instrumental reason to do things to us that we might not approve of.

Human beings in this model are threats, we could prevent the mathematical problem from being solved. 

This is a lesson that's also taught in many a myth.

King Midas wishes that everything he touches be turned into gold.

He touches his daughter, she turns into gold.

He touches his food, it turns into gold.

Now you might say, if a computer starts sticking electrodes into people's faces, we'd just shut it off.

B, why haven't the chimpanzees flicked the off switch to humanity, or the Neanderthals?

The point is, we should not be confident that we have this under control here. 

Right now, as I speak, I'm sure there is some employee out there somewhere who has been talked into handing out her account details by somebody claiming to be from the I.T.

Or it could output the blueprint to a really nifty technology, and when we implement it, it has some surreptitious side effect that the A.I.

Sooner or later, it will out. 

Now, I'm actually fairly optimistic that this problem can be solved.

We would thus leverage its intelligence as much as possible to solve the problem of value-loading. 

But it doesn't happen automatically.

The risk is that if somebody figures out how to crack the first challenge without also having cracked the additional challenge of ensuring perfect safety. 

But the more of the control problem that we solve in advance, the better the odds that the transition to the machine intelligence era will go well. 

