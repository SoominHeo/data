I work with children with autism.

Specifically, I make technologies to help them communicate. 

And because of this, they have a lot of difficulty with language. 

Let me tell you a little bit about why this is.

These are two other pictures of soup, but you can see that these are more abstract These are not quite as concrete.

And when you get to language, you see that it becomes a word whose look, the way it looks and the way it sounds, has absolutely nothing to do with what it started with, or what it represents, which is the bowl of soup.

So it's essentially a completely abstract, a completely arbitrary representation of something which is in the real world, and this is something that children with autism have an incredible amount of difficulty with.

Now that's why most of the people that work with children with autism -- speech therapists, educators -- what they do is, they try to help children with autism communicate not with words, but with pictures.

So if a child with autism wanted to say, "I want soup," that child would pick three different pictures, "I," "want," and "soup," and they would put these together, and then the therapist or the parent would understand that this is what the kid wants to say.

And this has been incredibly effective; for the last 30, 40 years people have been doing this.

So Avaz is essentially converting pictures, it's a translator, it converts pictures into speech. 

Now, this was very effective.

Let me explain this in a little more detail.

So there is another hidden abstraction here which children with autism find a lot of difficulty coping with, and that's the fact that you can modify words and you can arrange them to have different meanings, to convey different ideas.

Now, this is what we call grammar.

And grammar is incredibly powerful, because grammar is this one component of language which takes this finite vocabulary that all of us have and allows us to convey an infinite amount of information, an infinite amount of ideas.

It's the way in which you can put things together in order to convey anything you want to. 

And so after I developed Avaz, I worried for a very long time about how I could give grammar to children with autism.

The solution came to me from a very interesting perspective.

I happened to chance upon a child with autism conversing with her mom, and this is what happened.

So I was very excited by this, you know, hopping around all over the place, trying to figure out if I can convert all possible sentences that I hear into this.

And I found that this is not enough.

Why is this not enough?

This is not enough because if you wanted to convey something like negation, you want to say, "I don't want soup," then you can't do that by asking a question.

You do that by changing the word "want."

Again, if you wanted to say, "I wanted soup yesterday," you do that by converting the word "want" into "wanted."

It's a past tense.

So this is a flourish which I added to make the system complete.

This is a map of words joined together as questions and answers, and with these filters applied on top of them in order to modify them to represent certain nuances.

Let me show you this with a different example. 

The way that this particular system works, you can start with any part of this sentence.

I'm going to start with the word "tell."

So this is the word "tell."

Now this happened in the past, so I'm going to make that "told."

I told the carpenter I could not pay him. 

And there are two or three interesting things about this.

First of all, I could have started anywhere.

I didn't have to start with the word "tell."

I could have started anywhere in the sentence, and I could have made this entire thing.

The second thing is, if I wasn't an English speaker, if I was speaking in some other language, this map would actually hold true in any language.

So long as the questions are standardized, the map is actually independent of language.

I was trying out so many different combinations of this. 

And then I noticed something very interesting about FreeSpeech.

I was trying to convert language, convert sentences in English into sentences in FreeSpeech, and vice versa, and back and forth.

And I realized that this particular configuration, this particular way of representing language, it allowed me to actually create very concise rules that go between FreeSpeech on one side and English on the other.

So I could actually write this set of rules that translates from this particular representation into English.

And so I developed this thing.

And by putting these two pieces together, the representation and the engine, I was able to create an app, a technology for children with autism, that not only gives them words but also gives them grammar. 

So I tried this out with kids with autism, and I found that there was an incredible amount of identification.

In about 1997, about 15 years back, there were a group of scientists that were trying to understand how the brain processes language, and they found something very interesting.

They found that when you learn a language as a child, as a two-year-old, you learn it with a certain part of your brain, and when you learn a language as an adult -- for example, if I wanted to learn Japanese right now â€” a completely different part of my brain is used.

Now I don't know why that's the case, but my guess is that that's because when you learn a language as an adult, you almost invariably learn it through your native language, or through your first language.

So what's interesting about FreeSpeech is that when you create a sentence or when you create language, a child with autism creates language with FreeSpeech, they're not using this support language, they're not using this bridge language.

They're directly constructing the sentence. 

And so this gave me this idea.

Is it possible to use FreeSpeech not for children with autism but to teach language to people without disabilities?

And so I tried a number of experiments.

The first thing I did was I built a jigsaw puzzle in which these questions and answers are coded in the form of shapes, in the form of colors, and you have people putting these together and trying to understand how this works.

And I built an app out of it, a game out of it, in which children can play with words and with a reinforcement, a sound reinforcement of visual structures, they're able to learn language.

And this, this has a lot of potential, a lot of promise, and the government of India recently licensed this technology from us, and they're going to try it out with millions of different children trying to teach them English.

And the dream, the hope, the vision, really, is that when they learn English this way, they learn it with the same proficiency as their mother tongue. 

All right, let's talk about something else.

Let's talk about speech.

This is speech.

So speech is the primary mode of communication delivered between all of us.

Now what's interesting about speech is that speech is one-dimensional.

Why is it one-dimensional?

It's one-dimensional because it's sound.

It's also one-dimensional because our mouths are built that way.

Our mouths are built to create one-dimensional sound.

But if you think about the brain, the thoughts that we have in our heads are not one-dimensional.

I mean, we have these rich, complicated, multi-dimensional ideas.

Now, it seems to me that language is really the brain's invention to convert this rich, multi-dimensional thought on one hand into speech on the other hand.

Now what's interesting is that we do a lot of work in information nowadays, and almost all of that is done in the language domain.

Take Google, for example.

What if we could do this in FreeSpeech instead?

The data structure of thought.

That's a provocative idea. 

But let's look at this in a little more detail.

So this is the FreeSpeech ecosystem.

Now if you think about it, FreeSpeech, I told you, is completely language-independent.

It doesn't have any specific information in it which is about English.

So everything that this system knows about English is actually encoded into the engine.

That's a pretty interesting concept in itself.

You've encoded an entire human language into a software program.

And what's more interesting is the fact that the vast majority of the code in that engine is not really English-specific.

And that gives this interesting idea.

I mean, this is an incredibly attractive idea, especially for India.

We have so many different languages.

Language is beautiful.

I think it's the most beautiful of human creations.

I think it's the loveliest thing that our brains have invented.

It entertains, it educates, it enlightens, but what I like the most about language is that it empowers. 

I want to leave you with this.

This is a photograph of my collaborators, my earliest collaborators when I started working on language and autism and various other things.

The girl's name is Pavna, and that's her mother, Kalpana.

And everything that she's accomplished so far, finishing school, going to college, starting a company, collaborating with me to develop Avaz, all of these things she's done with nothing more than moving her eyes. 

Thank you.

Thank you.

Thank you.

Thank you.

