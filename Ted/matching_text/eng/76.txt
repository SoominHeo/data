This is essential for our own brains, and it's also pretty useful on a computer.

The machine perception algorithms, for example, that our team makes, are what enable your pictures on Google Photos to become searchable, based on what's in them.

So over the past year, our work on machine perception has also unexpectedly connected with the world of machine creativity and machine art. 

I think Michelangelo had a penetrating insight into to this dual relationship between perception and creativity.

The organ that does all the thinking and perceiving and imagining, of course, is the brain.

And I'd like to begin with a brief bit of history about what we know about brains.

But of course that sort of thing doesn't tell us very much about what's actually going on inside. 

This is from a bird brain.

And these structures, these cells that have these arborizations, these branches that can go very, very long distances -- this was very novel at the time.

They're reminiscent, of course, of wires.

That might have been obvious to some people in the 19th century; the revolutions of wiring and electricity were just getting underway.

But in many ways, these microanatomical drawings of Ram贸n y Cajal's, like this one, they're still in some ways unsurpassed. 

We're still more than a century later, trying to finish the job that Ram贸n y Cajal started.

These are raw data from our collaborators at the Max Planck Institute of Neuroscience.

And what our collaborators have done is to image little pieces of brain tissue.

The entire sample here is about one cubic millimeter in size, and I'm showing you a very, very small piece of it here.

That bar on the left is about one micron.

And these are consecutive slices through this very, very tiny block of tissue.

Just for comparison's sake, the diameter of an average strand of hair is about 100 microns.

So we're looking at something much, much smaller than a single strand of hair. 

And from these kinds of serial electron microscopy slices, one can start to make reconstructions in 3D of neurons that look like these.

So these are sort of in the same style as Ram贸n y Cajal.

It would be so crowded, so full of structure, of wiring all connecting one neuron to another. 

So Ram贸n y Cajal was a little bit ahead of his time, and progress on understanding the brain proceeded slowly over the next few decades.

But we knew that neurons used electricity, and by World War II, our technology was advanced enough to start doing real electrical experiments on live neurons to better understand how they worked.

This is the cortex that processes imagery that comes from the eye.

And for them, this looked like a circuit diagram.

So there are a lot of details in McCulloch and Pitts's circuit diagram that are not quite right.

But this basic idea that visual cortex works like a series of computational elements that pass information one to the next in a cascade, is essentially correct. 

But you should all understand that for a computer, this was pretty much impossible just a few years ago.

The classical computing paradigm is not one in which this task is easy to do. 

This neural network could be biological, inside our visual cortices, or, nowadays, we start to have the capability to model such neural networks on the computer.

And I'll show you what that actually looks like. 

The behavior of this network is characterized by the strengths of all of those synapses.

Those characterize the computational properties of this network.

And at the end of the day, you have a neuron or a small group of neurons that light up, saying, "bird."

Now I'm going to represent those three things -- the input pixels and the synapses in the neural network, and bird, the output -- by three variables: x, w and y.

There are maybe a million or so x's -- a million pixels in that image.

"Bird" is only four letters, right?

That's one equation.

There are three variables.

And we all know that if you have one equation, you can solve one variable by knowing the other two things.

So in that picture, the x and the w are known, and the y is the unknown.

This is a very, very complicated, very non-linear operation; it has no inverse.

So we have to figure out a way to solve the equation without a division operator.

And the way to do that is fairly straightforward.

You just say, let's play a little algebra trick, and move the six over to the right-hand side of the equation.

Now, we're still using multiplication.

And that zero -- let's think about it as an error.

And then the computer can sort of play Marco Polo, and drive down the error close to zero.

And this is the learning process. 

So remember that what's been going on here is that we've been taking a lot of known x's and known y's and solving for the w in the middle through an iterative process.

It's exactly the same way that we do our own learning.

We have many, many images as babies and we get told, "This is a bird; this is not a bird."

And over time, through iteration, we solve for w, we solve for those neural connections. 

In other words, you know that it's a bird, and you already have your neural network that you've trained on birds, but what is the picture of a bird?

It turns out that by using exactly the same error-minimization procedure, one can do that with the network trained to recognize birds, and the result turns out to be ... a picture of birds.

So this is a picture of birds generated entirely by a neural network that was trained to recognize birds, just by solving for x rather than solving for y, and doing that iteratively. 

And you get this strange, Escher-like morph from one animal to another. 

You can do this with other kinds of networks as well.

This is what happens if Alex uses his own face as a guide image during that optimization process to reconstruct my own face.

So you can see it's not perfect.

There's still quite a lot of work to do on how we optimize that optimization process.

But you start to get something more like a coherent face, rendered using my own face as a guide. 

When you're solving for x, you can begin with an x, that is itself already some other image.

That's what this little demonstration is.

And the more time you spend looking at this, the more things you also will see in the clouds.

You could also use the face network to hallucinate into this, and you get some pretty crazy stuff. 

And in this way, you can get a sort of fugue state of the network, I suppose, or a sort of free association, in which the network is eating its own tail.

So every image is now the basis for, "What do I think I see next?

I've shown you purely visual examples because they're really fun to look at.

It's not a purely visual technology.

And that poetry neural network has been trained on a large corpus of 20th-century poetry.

And the poetry is, you know, I think, kind of not bad, actually. 

Also, I think that perception and creativity are by no means uniquely human.

And finally, computing began as an exercise in designing intelligent machinery.

And I think that computing is not just about accounting or playing Candy Crush or something.

Thank you very much. 

