id="t-1000"&&I'm Dr. David Hanson, and I build robots with character.
id="t-4000"&&And by that, I mean that I develop robots that are characters, but also robots that will eventually come to empathize with you.
id="t-13000"&&So we're starting with a variety of technologies that have converged into these conversational character robots that can see faces, make eye contact with you, make a full range of facial expressions, understand speech and begin to model how you're feeling and who you are, and build a relationship with you. 

id="t-31000"&&I developed a series of technologies that allowed the robots to make more realistic facial expressions than previously achieved, on lower power, which enabled the walking biped robots, the first androids.
id="t-42000"&&So, it's a full range of facial expressions simulating all the major muscles in the human face, running on very small batteries, extremely lightweight. 

id="t-50000"&&The materials that allowed the battery-operated facial expressions is a material that we call Frubber, and it actually has three major innovations in the material that allow this to happen.
id="t-59000"&&One is hierarchical pores, and the other is a macro-molecular nanoscale porosity in the material. 

id="t-65000"&&There he's starting to walk.
id="t-68000"&&This is at the Korean Advanced Institute of Science and Technology.
id="t-68000"&&This is at the Korean Advanced Institute of Science and Technology.
id="t-68000"&&This is at the Korean Advanced Institute of Science and Technology.
id="t-75000"&&So the goal here is to achieve sentience in machines, and not just sentience, but empathy. 

id="t-82000"&&We're working with the Machine Perception Laboratory at the U.C.
id="t-82000"&&We're working with the Machine Perception Laboratory at the U.C.
id="t-86000"&&They have this really remarkable facial expression technology that recognizes facial expressions, what facial expressions you're making.
id="t-93000"&&It also recognizes where you're looking, your head orientation.
id="t-96000"&&We're emulating all the major facial expressions, and then controlling it with the software that we call the Character Engine.
id="t-102000"&&And here is a little bit of the technology that's involved in that. 

id="t-106000"&&In fact, right now -- plug it from here, and then plug it in here, and now let's see if it gets my facial expressions.
id="t-106000"&&In fact, right now -- plug it from here, and then plug it in here, and now let's see if it gets my facial expressions.
id="t-106000"&&In fact, right now -- plug it from here, and then plug it in here, and now let's see if it gets my facial expressions.
id="t-122000"&&(Laughter) Now I'm frowning.
id="t-126000"&&And this is really heavily backlit.
id="t-130000"&&Okay, here we go.
id="t-132000"&&Oh, it's so sad.
id="t-134000"&&Okay, so you smile, frowning.
id="t-137000"&&So his perception of your emotional states is very important for machines to effectively become empathetic. 

id="t-143000"&&Machines are becoming devastatingly capable of things like killing.
id="t-143000"&&Machines are becoming devastatingly capable of things like killing.
id="t-150000"&&Those machines have no place for empathy.
id="t-152000"&&And there is billions of dollars being spent on that.
id="t-154000"&&Character robotics could plant the seed for robots that actually have empathy.
id="t-158000"&&So, if they achieve human level intelligence or, quite possibly, greater than human levels of intelligence, this could be the seeds of hope for our future. 

id="t-167000"&&So, we've made 20 robots in the last eight years, during the course of getting my Ph.D. And then I started Hanson Robotics, which has been developing these things for mass manufacturing.
id="t-177000"&&This is one of our robots that we showed at Wired NextFest a couple of years ago.
id="t-181000"&&And it sees multiple people in a scene, remembers where individual people are, and looks from person to person, remembering people. 

id="t-190000"&&So, we're involving two things.
id="t-192000"&&One, the perception of people, and two, the natural interface, the natural form of the interface, so that it's more intuitive for you to interact with the robot.
id="t-203000"&&You start to believe that it's alive and aware. 

id="t-206000"&&So one of my favorite projects was bringing all this stuff together in an artistic display of an android portrait of science-fiction writer Philip K. Dick, who wrote great works like, "Do Androids Dream of Electric Sheep?"
id="t-217000"&&which was the basis of the movie "Bladerunner."
id="t-219000"&&In these stories, robots often think that they're human, and they sort of come to life.
id="t-224000"&&So we put his writings, letters, his interviews, correspondences, into a huge database of thousands of pages, and then used some natural language processing to allow you to actually have a conversation with him.
id="t-236000"&&And it was kind of spooky, because he would say these things that just sounded like they really understood you. 

id="t-241000"&&And this is one of the most exciting projects that we're developing, which is a little character that's a spokesbot for friendly artificial intelligence, friendly machine intelligence.
id="t-250000"&&And we're getting this mass-manufactured.
id="t-252000"&&We specked it out to actually be doable with a very, very low-cost bill of materials, so that it can become a childhood companion for kids.
id="t-262000"&&Interfacing with the Internet, it gets smarter over the years.
id="t-265000"&&As artificial intelligence evolves, so does his intelligence. 

Chris Anderson: Thank you so much.
Chris Anderson: Thank you so much.
id="t-270000"&&(Applause) 

