id="t-0"&&If you ask people about what part of psychology do they think is hard, and you say, "Well, what about thinking and emotions?"
id="t-9000"&&Most people will say, "Emotions are terribly hard.
id="t-9000"&&Most people will say, "Emotions are terribly hard.
id="t-9000"&&Most people will say, "Emotions are terribly hard.
id="t-18000"&&But thinking is really very straightforward: it's just sort of some kind of logical reasoning, or something.
id="t-24000"&&But that's not the hard part."

id="t-27000"&&So here's a list of problems that come up.
id="t-29000"&&One nice problem is, what do we do about health?
id="t-32000"&&The other day, I was reading something, and the person said probably the largest single cause of disease is handshaking in the West.
id="t-42000"&&And there was a little study about people who don't handshake, and comparing them with ones who do handshake.
id="t-49000"&&And I haven't the foggiest idea of where you find the ones that don't handshake, because they must be hiding.
id="t-57000"&&And the people who avoid that have 30 percent less infectious disease or something.
id="t-65000"&&Or maybe it was 31 and a quarter percent.
id="t-68000"&&So if you really want to solve the problem of epidemics and so forth, let's start with that.
id="t-68000"&&So if you really want to solve the problem of epidemics and so forth, let's start with that.
id="t-80000"&&And I think the only way to avoid it is to have some horrible visible disease, and then you don't have to explain. 

id="t-90000"&&Education: how do we improve education?
id="t-94000"&&Well, the single best way is to get them to understand that what they're being told is a whole lot of nonsense.
id="t-101000"&&And then, of course, you have to do something about how to moderate that, so that anybody can -- so they'll listen to you.
id="t-108000"&&Pollution, energy shortage, environmental diversity, poverty.
id="t-108000"&&Pollution, energy shortage, environmental diversity, poverty.
id="t-108000"&&Pollution, energy shortage, environmental diversity, poverty.
id="t-116000"&&Okay, there're lots of problems to worry about. 

id="t-119000"&&Anyway, the question I think people should talk about -- and it's absolutely taboo -- is, how many people should there be?
id="t-126000"&&And I think it should be about 100 million or maybe 500 million.
id="t-133000"&&And then notice that a great many of these problems disappear.
id="t-138000"&&If you had 100 million people properly spread out, then if there's some garbage, you throw it away, preferably where you can't see it, and it will rot.
id="t-153000"&&Or you throw it into the ocean and some fish will benefit from it.
id="t-158000"&&The problem is, how many people should there be?
id="t-160000"&&And it's a sort of choice we have to make. 

id="t-163000"&&Most people are about 60 inches high or more, and there's these cube laws.
id="t-163000"&&Most people are about 60 inches high or more, and there's these cube laws.
id="t-176000"&&That would solve the problem, but I don't see anybody doing any research on making people smaller.
id="t-181000"&&Now, it's nice to reduce the population, but a lot of people want to have children.
id="t-186000"&&And there's one solution that's probably only a few years off.
id="t-186000"&&And there's one solution that's probably only a few years off.
id="t-186000"&&And there's one solution that's probably only a few years off.
id="t-186000"&&And there's one solution that's probably only a few years off.
id="t-186000"&&And there's one solution that's probably only a few years off.
id="t-186000"&&And there's one solution that's probably only a few years off.
id="t-186000"&&And there's one solution that's probably only a few years off.
id="t-186000"&&And there's one solution that's probably only a few years off.

id="t-243000"&&Timesharing is a little further off in the future.
id="t-246000"&&And there's this great novel that Arthur Clarke wrote twice, called "Against the Fall of Night" and "The City and the Stars."
id="t-253000"&&They're both wonderful and largely the same, except that computers happened in between.
id="t-258000"&&And Arthur was looking at this old book, and he said, "Well, that was wrong.
id="t-263000"&&The future must have some computers."
id="t-265000"&&So in the second version of it, there are 100 billion or 1,000 billion people on Earth, but they're all stored on hard disks or floppies, or whatever they have in the future.
id="t-280000"&&And you let a few million of them out at a time.
id="t-284000"&&A person comes out, they live for a thousand years doing whatever they do, and then, when it's time to go back for a billion years -- or a million, I forget, the numbers don't matter -- but there really aren't very many people on Earth at a time.
id="t-302000"&&And you get to think about yourself and your memories, and before you go back into suspension, you edit your memories and you change your personality and so forth.
id="t-312000"&&The plot of the book is that there's not enough diversity, so that the people who designed the city make sure that every now and then an entirely new person is created.
id="t-312000"&&The plot of the book is that there's not enough diversity, so that the people who designed the city make sure that every now and then an entirely new person is created.
id="t-312000"&&The plot of the book is that there's not enough diversity, so that the people who designed the city make sure that every now and then an entirely new person is created.

id="t-335000"&&I don't think the solutions that I proposed are good enough or smart enough.
id="t-340000"&&I think the big problem is that we're not smart enough to understand which of the problems we're facing are good enough.
id="t-348000"&&Therefore, we have to build super intelligent machines like HAL.
id="t-352000"&&As you remember, at some point in the book for "2001," HAL realizes that the universe is too big, and grand, and profound for those really stupid astronauts.
id="t-352000"&&As you remember, at some point in the book for "2001," HAL realizes that the universe is too big, and grand, and profound for those really stupid astronauts.
id="t-352000"&&As you remember, at some point in the book for "2001," HAL realizes that the universe is too big, and grand, and profound for those really stupid astronauts.
id="t-352000"&&As you remember, at some point in the book for "2001," HAL realizes that the universe is too big, and grand, and profound for those really stupid astronauts.
id="t-376000"&&I think that we're pretty smart, as compared to chimpanzees, but we're not smart enough to deal with the colossal problems that we face, either in abstract mathematics or in figuring out economies, or balancing the world around.
id="t-394000"&&So one thing we can do is live longer.
id="t-397000"&&And nobody knows how hard that is, but we'll probably find out in a few years.
id="t-397000"&&And nobody knows how hard that is, but we'll probably find out in a few years.
id="t-397000"&&And nobody knows how hard that is, but we'll probably find out in a few years.
id="t-416000"&&But lots of people now live to 90 or 100, unless they shake hands too much or something like that.
id="t-423000"&&And so maybe if we lived 200 years, we could accumulate enough skills and knowledge to solve some problems.
id="t-433000"&&So that's one way of going about it.
id="t-433000"&&So that's one way of going about it.
id="t-433000"&&So that's one way of going about it.
id="t-433000"&&So that's one way of going about it.
id="t-433000"&&So that's one way of going about it.

id="t-465000"&&What I think is that the gene counters don't know what they're doing yet.
id="t-468000"&&And whatever you do, don't read anything about genetics that's published within your lifetime, or something.
id="t-173000"&&(Laughter) The stuff has a very short half-life, same with brain science.
id="t-481000"&&And so it might be that if we just fix four or five genes, we can live 200 years.
id="t-489000"&&Or it might be that it's just 30 or 40, and I doubt that it's several hundred.
id="t-494000"&&So this is something that people will be discussing and lots of ethicists -- you know, an ethicist is somebody who sees something wrong with whatever you have in mind.
id="t-173000"&&(Laughter) And it's very hard to find an ethicist who considers any change worth making, because he says, what about the consequences?
id="t-515000"&&And, of course, we're not responsible for the consequences of what we're doing now, are we?
id="t-515000"&&And, of course, we're not responsible for the consequences of what we're doing now, are we?
id="t-524000"&&And yet two random people will mate and have this child, and both of them have some pretty rotten genes, and the child is likely to come out to be average.
id="t-535000"&&Which, by chimpanzee standards, is very good indeed. 

id="t-541000"&&If we do have longevity, then we'll have to face the population growth problem anyway.
id="t-541000"&&If we do have longevity, then we'll have to face the population growth problem anyway.
id="t-554000"&&And so there won't be any workforce.
id="t-557000"&&And one of the things Laurie Garrett pointed out, and others have, is that a society that doesn't have people of working age is in real trouble.
id="t-557000"&&And one of the things Laurie Garrett pointed out, and others have, is that a society that doesn't have people of working age is in real trouble.
id="t-575000"&&And when I'm talking about a long lifetime, of course, I don't want somebody who's 200 years old to be like our image of what a 200-year-old is -- which is dead, actually. 

id="t-587000"&&You know, there's about 400 different parts of the brain which seem to have different functions.
id="t-591000"&&Nobody knows how most of them work in detail, but we do know that there're lots of different things in there.
id="t-591000"&&Nobody knows how most of them work in detail, but we do know that there're lots of different things in there.
id="t-591000"&&Nobody knows how most of them work in detail, but we do know that there're lots of different things in there.
id="t-604000"&&And so if you think of yourself as a sort of city with a hundred resources, then, when you're afraid, for example, you may discard your long-range goals, but you may think deeply and focus on exactly how to achieve that particular goal.
id="t-604000"&&And so if you think of yourself as a sort of city with a hundred resources, then, when you're afraid, for example, you may discard your long-range goals, but you may think deeply and focus on exactly how to achieve that particular goal.
id="t-604000"&&And so if you think of yourself as a sort of city with a hundred resources, then, when you're afraid, for example, you may discard your long-range goals, but you may think deeply and focus on exactly how to achieve that particular goal.
id="t-629000"&&And when you're hungry, food becomes more attractive, and so forth.
id="t-633000"&&So I see emotions as highly evolved subsets of your capability.
id="t-633000"&&So I see emotions as highly evolved subsets of your capability.
id="t-633000"&&So I see emotions as highly evolved subsets of your capability.

id="t-650000"&&So thinking of emotions as the opposite of -- as something less than thinking is immensely productive.
id="t-650000"&&So thinking of emotions as the opposite of -- as something less than thinking is immensely productive.
id="t-661000"&&And I guess I better skip all the rest of this, which are some details on how we might make those smart machines and -- (Laughter) -- and the main idea is in fact that the core of a really smart machine is one that recognizes that a certain kind of problem is facing you.
id="t-684000"&&This is a problem of such and such a type, and therefore there's a certain way or ways of thinking that are good for that problem.
id="t-694000"&&So I think the future, main problem of psychology is to classify types of predicaments, types of situations, types of obstacles and also to classify available and possible ways to think and pair them up.
id="t-708000"&&So you see, it's almost like a Pavlovian -- we lost the first hundred years of psychology by really trivial theories, where you say, how do people learn how to react to a situation?
id="t-708000"&&So you see, it's almost like a Pavlovian -- we lost the first hundred years of psychology by really trivial theories, where you say, how do people learn how to react to a situation?
id="t-734000"&&Saying, not what are the situations, but what are the kinds of problems and what are the kinds of strategies, how do you learn them, how do you connect them up, how does a really creative person invent a new way of thinking out of the available resources and so forth. 

id="t-750000"&&So, I think in the next 20 years, if we can get rid of all of the traditional approaches to artificial intelligence, like neural nets and genetic algorithms and rule-based systems, and just turn our sights a little bit higher to say, can we make a system that can use all those things for the right kind of problem?
id="t-750000"&&So, I think in the next 20 years, if we can get rid of all of the traditional approaches to artificial intelligence, like neural nets and genetic algorithms and rule-based systems, and just turn our sights a little bit higher to say, can we make a system that can use all those things for the right kind of problem?
id="t-774000"&&Genetic algorithms are great for certain things; I suspect I know what they're bad at, and I won't tell you.
id="t-173000"&&(Laughter) 

id="t-782000"&&Thank you.
id="t-784000"&&(Applause) 

